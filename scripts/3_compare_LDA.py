"""
Contrast lexical purity rankings with LDA topic wordlists over Brown corpus.

Inputs:
    data/processed/brown_clean.jsonl and data/results/purity_baseline_clean.csv
    generated by earlier scripts in this pipeline.
Outputs:
    Console summaries of LDA topics, purity leaders, and their overlaps plus
    optional CSVs (data/results/lda_k2_topics.csv and
    data/results/lda_k2_lp_assignment.csv) when --save_csv is set.
Usage:
    python scripts/3_compare_LDA.py [--n_topics 2 --n_top_words 40 --save_csv]
"""

import os
import json
import argparse
from collections import Counter

import numpy as np
import pandas as pd

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation

DATA_DIR      = "data"
PROCESSED_DIR = os.path.join(DATA_DIR, "processed")
RESULTS_DIR   = os.path.join(DATA_DIR, "results")
os.makedirs(RESULTS_DIR, exist_ok=True)


def load_docs(clean_jsonl_path):
    """
    Load the preprocessed documents from JSONL format.

    Args:
        clean_jsonl_path: Path to data/processed/brown_clean.jsonl.
    Returns:
        List of dictionaries with id, genre, n_tokens, and tokens keys.
    """
    docs = []
    with open(clean_jsonl_path, "r") as f:
        for line in f:
            docs.append(json.loads(line))
    return docs


def build_corpus_texts(docs):
    """
    Turn tokenized documents into whitespace-joined strings for vectorization.

    Args:
        docs: Sequence produced by load_docs.
    Returns:
        List of strings ready for CountVectorizer.
    """
    return [" ".join(d["tokens"]) for d in docs]


def main():
    """Parse CLI args, fit the LDA model, and print comparison summaries."""
    parser = argparse.ArgumentParser()
    parser.add_argument("--n_topics", type=int, default=2, help="Number of LDA topics (default: 2)")
    parser.add_argument("--n_top_words", type=int, default=40,
                        help="Top-N words to show per topic (default: 40)")
    parser.add_argument("--n_lp_terms", type=int, default=40,
                        help="Top-N lexical purity terms to compare (default: 40)")
    parser.add_argument("--random_state", type=int, default=42,
                        help="Random seed for LDA")
    parser.add_argument("--save_csv", action="store_true",
                        help="If set, save topic-word table to CSV")
    args = parser.parse_args()

    # ---------------- Load corpus and baseline purity ----------------
    clean_jsonl_path = os.path.join(PROCESSED_DIR, "brown_clean.jsonl")
    purity_path      = os.path.join(RESULTS_DIR, "purity_baseline_clean.csv")

    print(f"\nLoading docs from {clean_jsonl_path} ...")
    docs = load_docs(clean_jsonl_path)
    print(f"Loaded {len(docs):,} documents.")

    print(f"Loading purity baseline from {purity_path} ...")
    df_purity = pd.read_csv(purity_path)

    # Use the exact term set from purity_baseline as vocabulary
    vocab_terms = df_purity["term"].tolist()
    print(f"Vocabulary size from purity_baseline: {len(vocab_terms):,} terms")

    # ---------------- Build document-term matrix ----------------
    texts = build_corpus_texts(docs)

    # CountVectorizer with fixed vocabulary ensures alignment term↔column
    vectorizer = CountVectorizer(
        vocabulary=vocab_terms,
        lowercase=False,      # already lowercased in preprocessing
        token_pattern=r"(?u)\b\w+\b"  # basic word pattern
    )

    print("\nVectorizing documents...")
    X = vectorizer.fit_transform(texts)  # fit_transform is fine; vocab is fixed
    print(f"Doc-term matrix shape: {X.shape[0]:,} docs × {X.shape[1]:,} terms")

    # Build inverse vocabulary: col_idx -> term
    inv_vocab = {idx: term for term, idx in vectorizer.vocabulary_.items()}

    # ---------------- Fit LDA(K=2) ----------------
    print(f"\nFitting LDA with K={args.n_topics} topics...")
    lda = LatentDirichletAllocation(
        n_components=args.n_topics,
        random_state=args.random_state,
        learning_method="batch",
        max_iter=50,
        n_jobs=-1,
    )
    lda.fit(X)

    components = lda.components_  # shape: (K, V)
    K, V = components.shape
    print(f"LDA fitted. Components shape: {K} × {V}")

    # ---------------- Extract top-N words per topic ----------------
    n_top = args.n_top_words
    topic_word_rows = []  # for optional CSV

    print("\n=== Top words per topic ===\n")
    for k in range(K):
        topic = components[k]
        # Normalized probabilities for readability
        topic_probs = topic / topic.sum()

        top_idx = np.argsort(topic)[::-1][:n_top]
        print(f"Topic {k}:")
        for rank, idx in enumerate(top_idx, start=1):
            term = inv_vocab[idx]
            weight = topic_probs[idx]
            print(f"  {rank:2d}. {term:20s}  ({weight:.4f})")
            topic_word_rows.append({
                "topic": k,
                "rank": rank,
                "term": term,
                "weight": float(weight),
            })
        print()

    # ---------------- Compare with top-N LP terms ----------------
    n_lp = args.n_lp_terms
    df_sorted = df_purity.sort_values("G_true", ascending=False)
    top_lp_terms = df_sorted["term"].head(n_lp).tolist()
    print(f"Top {n_lp} LP terms by G_true:")
    print(", ".join(top_lp_terms))
    print()

    # Build sets of topic words for overlap checks
    topic_sets = []
    for k in range(K):
        topic = components[k]
        top_idx = np.argsort(topic)[::-1][:n_top]
        topic_terms = {inv_vocab[idx] for idx in top_idx}
        topic_sets.append(topic_terms)

    lp_set = set(top_lp_terms)

    print("=== Overlap of LP top terms with LDA topics ===\n")
    for k, tset in enumerate(topic_sets):
        overlap = lp_set & tset
        jaccard = len(overlap) / float(len(lp_set | tset)) if (lp_set | tset) else 0.0
        print(f"Topic {k}:")
        print(f"  Overlap count: {len(overlap)}")
        print(f"  Jaccard(lptop, topic{k}_top): {jaccard:.4f}")
        if overlap:
            print(f"  Overlapping terms: {', '.join(sorted(overlap))}")
        print()

    # ---------------- Optional: assign each LP top term to its strongest topic ----------------
    print("=== LP top terms: strongest LDA topic assignment ===\n")
    # Normalize components for probability view
    comp_norm = components / components.sum(axis=1, keepdims=True)

    # Build mapping term -> column index
    term2idx = vectorizer.vocabulary_
    rows_assign = []
    for term in top_lp_terms:
        idx = term2idx.get(term, None)
        if idx is None:
            rows_assign.append({"term": term, "best_topic": None, "best_weight": None})
            continue
        topic_weights = comp_norm[:, idx]
        best_k = int(np.argmax(topic_weights))
        best_w = float(topic_weights[best_k])
        rows_assign.append({"term": term, "best_topic": best_k, "best_weight": best_w})

    df_assign = pd.DataFrame(rows_assign)
    print(df_assign.to_string(index=False))
    print()

    # ---------------- Optional CSV output ----------------
    if args.save_csv:
        out_topics_csv = os.path.join(RESULTS_DIR, "lda_k2_topics.csv")
        pd.DataFrame(topic_word_rows).to_csv(out_topics_csv, index=False)
        print(f"Topic-word table saved to {out_topics_csv}")

        out_assign_csv = os.path.join(RESULTS_DIR, "lda_k2_lp_assignment.csv")
        df_assign.to_csv(out_assign_csv, index=False)
        print(f"LP term topic-assignment table saved to {out_assign_csv}")


if __name__ == "__main__":
    main()
